{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5175712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from LOD_paper_tools import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "fp = \"G:\\\\My Drive\\\\Darby Work\\\\Ytsma and Dyar 2021 (LOD paper)\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec51b8b",
   "metadata": {},
   "source": [
    "#### Compositions and reference keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974ccacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate comps\n",
    "comps_path = fp + \"tables\\\\TableS1_sample_compositions.xlsx\"\n",
    "lanl_comps = pd.read_excel(comps_path, sheet_name = \"LANL\")\n",
    "mhc_comps = pd.read_excel(comps_path, sheet_name = \"MHC\")\n",
    "comps = pd.merge(mhc_comps, lanl_comps, how = \"outer\") # merge comps\n",
    "comps.columns = comps.columns.map(lambda x: x.split()[0])\n",
    "comps = comps.drop_duplicates(subset = 'Sample') # remove duplicates\n",
    "comps['Sample'] = comps['Sample'].astype(str)\n",
    "comps = comps.sort_values(by='Sample')\n",
    "comps = comps.replace(np.nan, \"\", regex=True)\n",
    "cols = comps.columns.drop('Sample')\n",
    "comps[cols] = comps[cols].apply(pd.to_numeric) # make columns numeric\n",
    "\n",
    "# make dictionary of spectrum names to sample names\n",
    "key_path = fp + \"ChemLIBS_spectrum_no_to_name.csv\"\n",
    "mhc_key = pd.read_csv(key_path)\n",
    "mhc_key = pd.Series(mhc_key.Sample.values, index=mhc_key.pkey).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ddff1",
   "metadata": {},
   "source": [
    "## Calculate sensitivities\n",
    "### Braga method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26857ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define blank/noise regions in ChemLIBS and ChemCam spectra\n",
    "blank_braga = pd.read_csv(fp + \"figures\\\\braga_noise_regions.csv\") \n",
    "\n",
    "# import all spectra\n",
    "cl_earth = pd.read_csv(fp + \"CL_all_Earth_spectra.csv\")\n",
    "cl_mars = pd.read_csv(fp + \"CL_all_Mars_spectra.csv\")\n",
    "cl_vacuum = pd.read_csv(fp + \"CL_all_Vacuum_spectra.csv\")\n",
    "cc_mars = pd.read_csv(fp + \"CC_all_Mars_spectra.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e990aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets cleaned:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520bda4167ef4c5ca15627476ccfbb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows cleaned:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52073bfe155d470c8fc059199c62480b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows cleaned:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8983e680f44932839239c3c7777c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows cleaned:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddfa084aaf144329021e10f47499a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows cleaned:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ef71a8d97c4560b4e335ea223541a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_list = [cc_mars, cl_earth, cl_mars, cl_vacuum]\n",
    "\n",
    "print(\"Datasets cleaned:\")\n",
    "for df in tqdm(df_list):\n",
    "    print(\"Rows cleaned:\")\n",
    "    for row in tqdm(df.index):\n",
    "        nm = df['wave'][row]\n",
    "        # remove rows below first region\n",
    "        if nm < blank_braga['start'][0]:\n",
    "            df.drop(row, axis = 'index', inplace=True)\n",
    "        # remove rows after last region\n",
    "        elif nm > blank_braga['stop'][len(blank_braga)-1]:\n",
    "            df.drop(row, axis = 'index', inplace=True)\n",
    "        # remove rows between the regions\n",
    "        for region in range(len(blank_braga)-1):\n",
    "            if (nm > blank_braga['stop'][region]) & (nm < blank_braga['start'][region+1]):\n",
    "                df.drop(row, axis = 'index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698f9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise stdev across each row, take average\n",
    "cc_mars_sens = round(cc_mars.set_index('wave').std(axis=1).mean(),9)\n",
    "cl_mars_sens = round(cl_mars.set_index('wave').std(axis=1).mean(),9)\n",
    "cl_earth_sens = round(cl_earth.set_index('wave').std(axis=1).mean(),9)\n",
    "cl_vacuum_sens = round(cl_vacuum.set_index('wave').std(axis=1).mean(),9)\n",
    "\n",
    "sens_list = [cc_mars_sens, cl_mars_sens, cl_earth_sens, cl_vacuum_sens]\n",
    "inst_list = [\"LANL\", 'ChemLIBS', 'ChemLIBS', 'ChemLIBS']\n",
    "atm_list = [\"Mars\", \"Mars\", \"Earth\", \"Vacuum\"]\n",
    "\n",
    "# make dataframe\n",
    "braga_sensitivities = pd.DataFrame({\n",
    "    \"instrument\" : inst_list,\n",
    "    \"atmosphere\" : atm_list,\n",
    "    \"sensitivity\" : sens_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba897c",
   "metadata": {},
   "source": [
    "### Metals method\n",
    "#### LANL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbb1afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1fa5b7d861467a89da29cd9fef0f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read in LANL blank spectra\n",
    "folder = fp + \"LANL calculations\\\\metals background\\\\norm\\\\\"\n",
    "spectra_list = os.listdir(folder)[:9]\n",
    "spectra = {}\n",
    "sheet_list = [1,2,3,4]\n",
    "\n",
    "blank_list = []\n",
    "spectrum_n = []\n",
    "sens_list = []\n",
    "\n",
    "for file in tqdm(spectra_list):\n",
    "    # read data\n",
    "    path = (folder + \"\\\\\" + file)\n",
    "    name = file.split(\"_\")[0] + \"_\" + file.split(\"_\")[1]\n",
    "    spectra[name] = pd.read_excel(path, sheet_name = sheet_list)\n",
    "    \n",
    "    for sheet in sheet_list:\n",
    "        # remove extra columns for when I calculated by hand\n",
    "        spectra[name][sheet].drop(spectra[name][sheet].columns[[0,1,2]], axis=1, inplace=True)\n",
    "        \n",
    "        # calculate sensitivity\n",
    "        sensitivity = round(spectra[name][sheet].std(axis=1).mean(),9)\n",
    "        \n",
    "        # add to list\n",
    "        blank_list.append(name)\n",
    "        spectrum_n.append(sheet)\n",
    "        sens_list.append(sensitivity)\n",
    "        \n",
    "# make dataframe of all results\n",
    "lanl_sens_df = pd.DataFrame({\n",
    "    \"blank\" : blank_list,\n",
    "    \"spectrum\" : spectrum_n,\n",
    "    \"sensitivity\" : sens_list\n",
    "})\n",
    "\n",
    "# get average for LANL metals method\n",
    "lanl_metal_sens = round(lanl_sens_df['sensitivity'].mean(),9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32764b",
   "metadata": {},
   "source": [
    "#### ChemLIBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad305a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data = pd.read_excel(fp + \"ChemLIBS calculations\\\\background_metals_030421.xlsx\", sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc691924",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_list = np.arange(start = 1, stop = len(cl_data))\n",
    "\n",
    "element_list = []\n",
    "atm_list = []\n",
    "sens_list = []\n",
    "\n",
    "for sheet in sheet_list:\n",
    "    # get relevant info\n",
    "    name = list(cl_data.keys())[sheet]\n",
    "    element = name.split(\"_\")[0]\n",
    "    atmosphere = name.split(\"_\")[1]\n",
    "    \n",
    "    # drop unneeded columns and rows\n",
    "    cl_data[name].drop(cl_data[name].columns[[0,1]], axis=1, inplace=True)\n",
    "    cl_data[name].drop(cl_data[name].index[[0]], inplace=True)\n",
    "    \n",
    "    # calculate sensitivity\n",
    "    sensitivity = round(cl_data[name].std(axis=1).mean(),9)\n",
    "\n",
    "    # add to list\n",
    "    element_list.append(element)\n",
    "    atm_list.append(atmosphere)\n",
    "    sens_list.append(sensitivity)\n",
    "\n",
    "# make dataframe of all results\n",
    "mhc_sens_df = pd.DataFrame({\n",
    "    \"element\" : element_list,\n",
    "    \"atmosphere\" : atm_list,\n",
    "    \"sensitivity\" : sens_list\n",
    "})\n",
    "\n",
    "# get average for MHC metals method\n",
    "mhc_mars_metal_sens = round(mhc_sens_df[mhc_sens_df['atmosphere'] == 'Mars']['sensitivity'].mean(), 9)\n",
    "mhc_earth_metal_sens = round(mhc_sens_df[mhc_sens_df['atmosphere'] == 'Earth']['sensitivity'].mean(), 9)\n",
    "mhc_vac_metal_sens = round(mhc_sens_df[mhc_sens_df['atmosphere'] == 'Vac']['sensitivity'].mean(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a64f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_list = [lanl_metal_sens, mhc_mars_metal_sens, mhc_earth_metal_sens, mhc_vac_metal_sens]\n",
    "inst_list = [\"LANL\", 'ChemLIBS', 'ChemLIBS', 'ChemLIBS']\n",
    "atm_list = [\"Mars\", \"Mars\", \"Earth\", \"Vacuum\"]\n",
    "\n",
    "# make dataframe\n",
    "metals_sensitivities = pd.DataFrame({\n",
    "    \"instrument\" : inst_list,\n",
    "    \"atmosphere\" : atm_list,\n",
    "    \"sensitivity\" : sens_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba308120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sensitivity results\n",
    "metals_sensitivities['method'] = \"metals\"\n",
    "braga_sensitivities['method'] = \"braga\"\n",
    "\n",
    "sensitivities = pd.concat([metals_sensitivities, braga_sensitivities]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49757f63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "envs = [['LANL', 'Mars'],['ChemLIBS', 'Mars'],['ChemLIBS', 'Earth'],['ChemLIBS', 'Vacuum']]\n",
    "\n",
    "for env in envs:\n",
    "    # calculate results per model\n",
    "    results_0_750 = get_results(sensitivities, env[0], env[1], '0-750')\n",
    "    results_250_1000 = get_results(sensitivities, env[0], env[1], '250-1000')\n",
    "    \n",
    "    # get aggregate results\n",
    "    detail_results = pd.concat([results_0_750, results_250_1000], ignore_index=True).drop(columns = 'vector')\n",
    "    avg = detail_results.groupby('element', as_index=False).mean()\n",
    "    stdev = detail_results.groupby('element', as_index=False).std()\n",
    "    sd_list = [i + '_sd' for i in stdev.columns[1:]]\n",
    "    sd_list.insert(0, 'element')\n",
    "    stdev.columns = sd_list\n",
    "    avg_results = pd.merge(avg, stdev, how='outer',on='element')\n",
    "    \n",
    "    # add environment information\n",
    "    detail_results.insert(loc=1, column='instrument', value=env[0])\n",
    "    detail_results.insert(loc=2, column='atmosphere', value=env[1])\n",
    "    avg_results.insert(loc=1, column='instrument', value=env[0])\n",
    "    avg_results.insert(loc=2, column='atmosphere', value=env[1])\n",
    "    \n",
    "    # update full table\n",
    "    full_avg_results = avg_results if env == envs[0] else pd.concat([full_avg_results, avg_results], ignore_index=True)\n",
    "    full_detail_results = detail_results if env == envs[0] else pd.concat([full_detail_results, detail_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ea8f7",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38833028",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = fp + \"averaged_LOD_RMSEP_results.csv\"\n",
    "detail_path = fp + \"detailed_LOD_RMSEP_results.csv\"\n",
    "full_avg_results.to_csv(full_path, index=False)\n",
    "full_detail_results.to_csv(detail_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
